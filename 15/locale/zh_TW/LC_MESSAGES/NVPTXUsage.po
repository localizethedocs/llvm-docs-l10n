# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2003-2025, LLVM Project
# This file is distributed under the same license as the LLVM package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: LLVM 15\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-10-07 18:11+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: zh_TW\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../NVPTXUsage.rst:3
msgid "User Guide for NVPTX Back-end"
msgstr ""

#: ../../../NVPTXUsage.rst:11
msgid "Introduction"
msgstr ""

#: ../../../NVPTXUsage.rst:13
msgid ""
"To support GPU programming, the NVPTX back-end supports a subset of LLVM IR "
"along with a defined set of conventions used to represent GPU programming "
"concepts. This document provides an overview of the general usage of the "
"back- end, including a description of the conventions used and the set of "
"accepted LLVM IR."
msgstr ""

#: ../../../NVPTXUsage.rst:21
msgid ""
"This document assumes a basic familiarity with CUDA and the PTX assembly "
"language. Information about the CUDA Driver API and the PTX assembly "
"language can be found in the `CUDA documentation <http://docs.nvidia.com/"
"cuda/index.html>`_."
msgstr ""

#: ../../../NVPTXUsage.rst:29
msgid "Conventions"
msgstr ""

#: ../../../NVPTXUsage.rst:32
msgid "Marking Functions as Kernels"
msgstr ""

#: ../../../NVPTXUsage.rst:34
msgid ""
"In PTX, there are two types of functions: *device functions*, which are only "
"callable by device code, and *kernel functions*, which are callable by host "
"code. By default, the back-end will emit device functions. Metadata is used "
"to declare a function as a kernel function. This metadata is attached to the "
"``nvvm.annotations`` named metadata object, and has the following format:"
msgstr ""

#: ../../../NVPTXUsage.rst:44
msgid ""
"The first parameter is a reference to the kernel function. The following "
"example shows a kernel function calling a device function in LLVM IR. The "
"function ``@my_kernel`` is callable from host code, but ``@my_fmad`` is not."
msgstr ""

#: ../../../NVPTXUsage.rst:66
msgid "When compiled, the PTX kernel functions are callable by host-side code."
msgstr ""

#: ../../../NVPTXUsage.rst:72 ../../../NVPTXUsage.rst:566
msgid "Address Spaces"
msgstr ""

#: ../../../NVPTXUsage.rst:74
msgid "The NVPTX back-end uses the following address space mapping:"
msgstr ""

#: ../../../NVPTXUsage.rst:77
msgid "Address Space"
msgstr ""

#: ../../../NVPTXUsage.rst:77
msgid "Memory Space"
msgstr ""

#: ../../../NVPTXUsage.rst:79
msgid "0"
msgstr ""

#: ../../../NVPTXUsage.rst:79
msgid "Generic"
msgstr ""

#: ../../../NVPTXUsage.rst:80
msgid "1"
msgstr ""

#: ../../../NVPTXUsage.rst:80
msgid "Global"
msgstr ""

#: ../../../NVPTXUsage.rst:81
msgid "2"
msgstr ""

#: ../../../NVPTXUsage.rst:81
msgid "Internal Use"
msgstr ""

#: ../../../NVPTXUsage.rst:82
msgid "3"
msgstr ""

#: ../../../NVPTXUsage.rst:82
msgid "Shared"
msgstr ""

#: ../../../NVPTXUsage.rst:83
msgid "4"
msgstr ""

#: ../../../NVPTXUsage.rst:83
msgid "Constant"
msgstr ""

#: ../../../NVPTXUsage.rst:84
msgid "5"
msgstr ""

#: ../../../NVPTXUsage.rst:84
msgid "Local"
msgstr ""

#: ../../../NVPTXUsage.rst:87
msgid ""
"Every global variable and pointer type is assigned to one of these address "
"spaces, with 0 being the default address space. Intrinsics are provided "
"which can be used to convert pointers between the generic and non-generic "
"address spaces."
msgstr ""

#: ../../../NVPTXUsage.rst:92
msgid ""
"As an example, the following IR will define an array ``@g`` that resides in "
"global device memory."
msgstr ""

#: ../../../NVPTXUsage.rst:99
msgid ""
"LLVM IR functions can read and write to this array, and host-side code can "
"copy data to it by name with the CUDA Driver API."
msgstr ""

#: ../../../NVPTXUsage.rst:102
msgid ""
"Note that since address space 0 is the generic space, it is illegal to have "
"global variables in address space 0.  Address space 0 is the default address "
"space in LLVM, so the ``addrspace(N)`` annotation is *required* for global "
"variables."
msgstr ""

#: ../../../NVPTXUsage.rst:109
msgid "Triples"
msgstr ""

#: ../../../NVPTXUsage.rst:111
msgid ""
"The NVPTX target uses the module triple to select between 32/64-bit code "
"generation and the driver-compiler interface to use. The triple architecture "
"can be one of ``nvptx`` (32-bit PTX) or ``nvptx64`` (64-bit PTX). The "
"operating system should be one of ``cuda`` or ``nvcl``, which determines the "
"interface used by the generated code to communicate with the driver.  Most "
"users will want to use ``cuda`` as the operating system, which makes the "
"generated PTX compatible with the CUDA Driver API."
msgstr ""

#: ../../../NVPTXUsage.rst:119
msgid "Example: 32-bit PTX for CUDA Driver API: ``nvptx-nvidia-cuda``"
msgstr ""

#: ../../../NVPTXUsage.rst:121
msgid "Example: 64-bit PTX for CUDA Driver API: ``nvptx64-nvidia-cuda``"
msgstr ""

#: ../../../NVPTXUsage.rst:128
msgid "NVPTX Intrinsics"
msgstr ""

#: ../../../NVPTXUsage.rst:131
msgid "Address Space Conversion"
msgstr ""

#: ../../../NVPTXUsage.rst:134
msgid "'``llvm.nvvm.ptr.*.to.gen``' Intrinsics"
msgstr ""

#: ../../../NVPTXUsage.rst:137 ../../../NVPTXUsage.rst:165
#: ../../../NVPTXUsage.rst:200 ../../../NVPTXUsage.rst:242
msgid "Syntax:"
msgstr ""

#: ../../../NVPTXUsage.rst:139 ../../../NVPTXUsage.rst:167
msgid ""
"These are overloaded intrinsics.  You can use these on any pointer types."
msgstr ""

#: ../../../NVPTXUsage.rst:149 ../../../NVPTXUsage.rst:177
#: ../../../NVPTXUsage.rst:219 ../../../NVPTXUsage.rst:249
msgid "Overview:"
msgstr ""

#: ../../../NVPTXUsage.rst:151
msgid ""
"The '``llvm.nvvm.ptr.*.to.gen``' intrinsics convert a pointer in a non-"
"generic address space to a generic address space pointer."
msgstr ""

#: ../../../NVPTXUsage.rst:155 ../../../NVPTXUsage.rst:187
msgid "Semantics:"
msgstr ""

#: ../../../NVPTXUsage.rst:157
msgid ""
"These intrinsics modify the pointer value to be a valid generic address "
"space pointer."
msgstr ""

#: ../../../NVPTXUsage.rst:162
msgid "'``llvm.nvvm.ptr.gen.to.*``' Intrinsics"
msgstr ""

#: ../../../NVPTXUsage.rst:179
msgid ""
"The '``llvm.nvvm.ptr.gen.to.*``' intrinsics convert a pointer in the generic "
"address space to a pointer in the target address space.  Note that these "
"intrinsics are only useful if the address space of the target address space "
"of the pointer is known.  It is not legal to use address space conversion "
"intrinsics to convert a pointer from one non-generic address space to "
"another non-generic address space."
msgstr ""

#: ../../../NVPTXUsage.rst:189
msgid ""
"These intrinsics modify the pointer value to be a valid pointer in the "
"target non-generic address space."
msgstr ""

#: ../../../NVPTXUsage.rst:194
msgid "Reading PTX Special Registers"
msgstr ""

#: ../../../NVPTXUsage.rst:197
msgid "'``llvm.nvvm.read.ptx.sreg.*``'"
msgstr ""

#: ../../../NVPTXUsage.rst:221
msgid ""
"The '``@llvm.nvvm.read.ptx.sreg.*``' intrinsics provide access to the PTX "
"special registers, in particular the kernel launch bounds.  These registers "
"map in the following way to CUDA builtins:"
msgstr ""

#: ../../../NVPTXUsage.rst:226
msgid "CUDA Builtin"
msgstr ""

#: ../../../NVPTXUsage.rst:226
msgid "PTX Special Register Intrinsic"
msgstr ""

#: ../../../NVPTXUsage.rst:228
msgid "``threadId``"
msgstr ""

#: ../../../NVPTXUsage.rst:228
msgid "``@llvm.nvvm.read.ptx.sreg.tid.*``"
msgstr ""

#: ../../../NVPTXUsage.rst:229
msgid "``blockIdx``"
msgstr ""

#: ../../../NVPTXUsage.rst:229
msgid "``@llvm.nvvm.read.ptx.sreg.ctaid.*``"
msgstr ""

#: ../../../NVPTXUsage.rst:230
msgid "``blockDim``"
msgstr ""

#: ../../../NVPTXUsage.rst:230
msgid "``@llvm.nvvm.read.ptx.sreg.ntid.*``"
msgstr ""

#: ../../../NVPTXUsage.rst:231
msgid "``gridDim``"
msgstr ""

#: ../../../NVPTXUsage.rst:231
msgid "``@llvm.nvvm.read.ptx.sreg.nctaid.*``"
msgstr ""

#: ../../../NVPTXUsage.rst:236
msgid "Barriers"
msgstr ""

#: ../../../NVPTXUsage.rst:239
msgid "'``llvm.nvvm.barrier0``'"
msgstr ""

#: ../../../NVPTXUsage.rst:251
msgid ""
"The '``@llvm.nvvm.barrier0()``' intrinsic emits a PTX ``bar.sync 0`` "
"instruction, equivalent to the ``__syncthreads()`` call in CUDA."
msgstr ""

#: ../../../NVPTXUsage.rst:256
msgid "Other Intrinsics"
msgstr ""

#: ../../../NVPTXUsage.rst:258
msgid ""
"For the full set of NVPTX intrinsics, please see the ``include/llvm/IR/"
"IntrinsicsNVVM.td`` file in the LLVM source tree."
msgstr ""

#: ../../../NVPTXUsage.rst:265
msgid "Linking with Libdevice"
msgstr ""

#: ../../../NVPTXUsage.rst:267
msgid ""
"The CUDA Toolkit comes with an LLVM bitcode library called ``libdevice`` "
"that implements many common mathematical functions. This library can be used "
"as a high-performance math library for any compilers using the LLVM NVPTX "
"target. The library can be found under ``nvvm/libdevice/`` in the CUDA "
"Toolkit and there is a separate version for each compute architecture."
msgstr ""

#: ../../../NVPTXUsage.rst:273
msgid ""
"For a list of all math functions implemented in libdevice, see `libdevice "
"Users Guide <http://docs.nvidia.com/cuda/libdevice-users-guide/index.html>`_."
msgstr ""

#: ../../../NVPTXUsage.rst:276
msgid ""
"To accommodate various math-related compiler flags that can affect code "
"generation of libdevice code, the library code depends on a special LLVM IR "
"pass (``NVVMReflect``) to handle conditional compilation within LLVM IR. "
"This pass looks for calls to the ``@__nvvm_reflect`` function and replaces "
"them with constants based on the defined reflection parameters. Such "
"conditional code often follows a pattern:"
msgstr ""

#: ../../../NVPTXUsage.rst:292
msgid "The default value for all unspecified reflection parameters is zero."
msgstr ""

#: ../../../NVPTXUsage.rst:294
msgid ""
"The ``NVVMReflect`` pass should be executed early in the optimization "
"pipeline, immediately after the link stage. The ``internalize`` pass is also "
"recommended to remove unused math functions from the resulting PTX. For an "
"input IR module ``module.bc``, the following compilation flow is recommended:"
msgstr ""

#: ../../../NVPTXUsage.rst:299
msgid "Save list of external functions in ``module.bc``"
msgstr ""

#: ../../../NVPTXUsage.rst:300
msgid "Link ``module.bc`` with ``libdevice.compute_XX.YY.bc``"
msgstr ""

#: ../../../NVPTXUsage.rst:301
msgid "Internalize all functions not in list from (1)"
msgstr ""

#: ../../../NVPTXUsage.rst:302
msgid "Eliminate all unused internal functions"
msgstr ""

#: ../../../NVPTXUsage.rst:303
msgid "Run ``NVVMReflect`` pass"
msgstr ""

#: ../../../NVPTXUsage.rst:304
msgid "Run standard optimization pipeline"
msgstr ""

#: ../../../NVPTXUsage.rst:308
msgid ""
"``linkonce`` and ``linkonce_odr`` linkage types are not suitable for the "
"libdevice functions. It is possible to link two IR modules that have been "
"linked against libdevice using different reflection variables."
msgstr ""

#: ../../../NVPTXUsage.rst:312
msgid ""
"Since the ``NVVMReflect`` pass replaces conditionals with constants, it will "
"often leave behind dead code of the form:"
msgstr ""

#: ../../../NVPTXUsage.rst:326
msgid ""
"Therefore, it is recommended that ``NVVMReflect`` is executed early in the "
"optimization pipeline before dead-code elimination."
msgstr ""

#: ../../../NVPTXUsage.rst:329
msgid ""
"The NVPTX TargetMachine knows how to schedule ``NVVMReflect`` at the "
"beginning of your pass manager; just use the following code when setting up "
"your pass manager:"
msgstr ""

#: ../../../NVPTXUsage.rst:341
msgid "Reflection Parameters"
msgstr ""

#: ../../../NVPTXUsage.rst:343
msgid ""
"The libdevice library currently uses the following reflection parameters to "
"control code generation:"
msgstr ""

#: ../../../NVPTXUsage.rst:347
msgid "Flag"
msgstr ""

#: ../../../NVPTXUsage.rst:347
msgid "Description"
msgstr ""

#: ../../../NVPTXUsage.rst:349
msgid "``__CUDA_FTZ=[0,1]``"
msgstr ""

#: ../../../NVPTXUsage.rst:349
msgid "Use optimized code paths that flush subnormals to zero"
msgstr ""

#: ../../../NVPTXUsage.rst:352
msgid ""
"The value of this flag is determined by the \"nvvm-reflect-ftz\" module "
"flag. The following sets the ftz flag to 1."
msgstr ""

#: ../../../NVPTXUsage.rst:360
msgid ""
"(``i32 4`` indicates that the value set here overrides the value in another "
"module we link with.  See the `LangRef <LangRef.html#module-flags-metadata>` "
"for details.)"
msgstr ""

#: ../../../NVPTXUsage.rst:365
msgid "Executing PTX"
msgstr ""

#: ../../../NVPTXUsage.rst:367
msgid ""
"The most common way to execute PTX assembly on a GPU device is to use the "
"CUDA Driver API. This API is a low-level interface to the GPU driver and "
"allows for JIT compilation of PTX code to native GPU machine code."
msgstr ""

#: ../../../NVPTXUsage.rst:371
msgid "Initializing the Driver API:"
msgstr ""

#: ../../../NVPTXUsage.rst:385
msgid "JIT compiling a PTX string to a device binary:"
msgstr ""

#: ../../../NVPTXUsage.rst:398
msgid ""
"For full examples of executing PTX assembly, please see the `CUDA Samples "
"<https://developer.nvidia.com/cuda-downloads>`_ distribution."
msgstr ""

#: ../../../NVPTXUsage.rst:403
msgid "Common Issues"
msgstr ""

#: ../../../NVPTXUsage.rst:406
msgid "ptxas complains of undefined function: __nvvm_reflect"
msgstr ""

#: ../../../NVPTXUsage.rst:408
msgid ""
"When linking with libdevice, the ``NVVMReflect`` pass must be used. See :ref:"
"`libdevice` for more information."
msgstr ""

#: ../../../NVPTXUsage.rst:413
msgid "Tutorial: A Simple Compute Kernel"
msgstr ""

#: ../../../NVPTXUsage.rst:415
msgid ""
"To start, let us take a look at a simple compute kernel written directly in "
"LLVM IR. The kernel implements vector addition, where each thread computes "
"one element of the output vector C from the input vectors A and B.  To make "
"this easier, we also assume that only a single CTA (thread block) will be "
"launched, and that it will be one dimensional."
msgstr ""

#: ../../../NVPTXUsage.rst:423
msgid "The Kernel"
msgstr ""

#: ../../../NVPTXUsage.rst:464
msgid ""
"We can use the LLVM ``llc`` tool to directly run the NVPTX code generator:"
msgstr ""

#: ../../../NVPTXUsage.rst:473
msgid ""
"If you want to generate 32-bit code, change ``p:64:64:64`` to ``p:32:32:32`` "
"in the module data layout string and use ``nvptx-nvidia-cuda`` as the target "
"triple."
msgstr ""

#: ../../../NVPTXUsage.rst:478
msgid "The output we get from ``llc`` (as of LLVM 3.4):"
msgstr ""

#: ../../../NVPTXUsage.rst:520
msgid "Dissecting the Kernel"
msgstr ""

#: ../../../NVPTXUsage.rst:522
msgid "Now let us dissect the LLVM IR that makes up this kernel."
msgstr ""

#: ../../../NVPTXUsage.rst:525
msgid "Data Layout"
msgstr ""

#: ../../../NVPTXUsage.rst:527
msgid ""
"The data layout string determines the size in bits of common data types, "
"their ABI alignment, and their storage size.  For NVPTX, you should use one "
"of the following:"
msgstr ""

#: ../../../NVPTXUsage.rst:531
msgid "32-bit PTX:"
msgstr ""

#: ../../../NVPTXUsage.rst:537
msgid "64-bit PTX:"
msgstr ""

#: ../../../NVPTXUsage.rst:545
msgid "Target Intrinsics"
msgstr ""

#: ../../../NVPTXUsage.rst:547
msgid ""
"In this example, we use the ``@llvm.nvvm.read.ptx.sreg.tid.x`` intrinsic to "
"read the X component of the current thread's ID, which corresponds to a read "
"of register ``%tid.x`` in PTX. The NVPTX back-end supports a large set of "
"intrinsics.  A short list is shown below; please see ``include/llvm/IR/"
"IntrinsicsNVVM.td`` for the full list."
msgstr ""

#: ../../../NVPTXUsage.rst:555
msgid "Intrinsic"
msgstr ""

#: ../../../NVPTXUsage.rst:555
msgid "CUDA Equivalent"
msgstr ""

#: ../../../NVPTXUsage.rst:557
msgid "``i32 @llvm.nvvm.read.ptx.sreg.tid.{x,y,z}``"
msgstr ""

#: ../../../NVPTXUsage.rst:557
msgid "threadIdx.{x,y,z}"
msgstr ""

#: ../../../NVPTXUsage.rst:558
msgid "``i32 @llvm.nvvm.read.ptx.sreg.ctaid.{x,y,z}``"
msgstr ""

#: ../../../NVPTXUsage.rst:558
msgid "blockIdx.{x,y,z}"
msgstr ""

#: ../../../NVPTXUsage.rst:559
msgid "``i32 @llvm.nvvm.read.ptx.sreg.ntid.{x,y,z}``"
msgstr ""

#: ../../../NVPTXUsage.rst:559
msgid "blockDim.{x,y,z}"
msgstr ""

#: ../../../NVPTXUsage.rst:560
msgid "``i32 @llvm.nvvm.read.ptx.sreg.nctaid.{x,y,z}``"
msgstr ""

#: ../../../NVPTXUsage.rst:560
msgid "gridDim.{x,y,z}"
msgstr ""

#: ../../../NVPTXUsage.rst:561
msgid "``void @llvm.nvvm.barrier0()``"
msgstr ""

#: ../../../NVPTXUsage.rst:561
msgid "__syncthreads()"
msgstr ""

#: ../../../NVPTXUsage.rst:568
msgid ""
"You may have noticed that all of the pointer types in the LLVM IR example "
"had an explicit address space specifier. What is address space 1? NVIDIA GPU "
"devices (generally) have four types of memory:"
msgstr ""

#: ../../../NVPTXUsage.rst:572
msgid "Global: Large, off-chip memory"
msgstr ""

#: ../../../NVPTXUsage.rst:573
msgid "Shared: Small, on-chip memory shared among all threads in a CTA"
msgstr ""

#: ../../../NVPTXUsage.rst:574
msgid "Local: Per-thread, private memory"
msgstr ""

#: ../../../NVPTXUsage.rst:575
msgid "Constant: Read-only memory shared across all threads"
msgstr ""

#: ../../../NVPTXUsage.rst:577
msgid ""
"These different types of memory are represented in LLVM IR as address "
"spaces. There is also a fifth address space used by the NVPTX code generator "
"that corresponds to the \"generic\" address space.  This address space can "
"represent addresses in any other address space (with a few exceptions).  "
"This allows users to write IR functions that can load/store memory using the "
"same instructions. Intrinsics are provided to convert pointers between the "
"generic and non-generic address spaces."
msgstr ""

#: ../../../NVPTXUsage.rst:585
msgid ""
"See :ref:`address_spaces` and :ref:`nvptx_intrinsics` for more information."
msgstr ""

#: ../../../NVPTXUsage.rst:589
msgid "Kernel Metadata"
msgstr ""

#: ../../../NVPTXUsage.rst:591
msgid ""
"In PTX, a function can be either a `kernel` function (callable from the host "
"program), or a `device` function (callable only from GPU code). You can "
"think of `kernel` functions as entry-points in the GPU program. To mark an "
"LLVM IR function as a `kernel` function, we make use of special LLVM "
"metadata. The NVPTX back-end will look for a named metadata node called "
"``nvvm.annotations``. This named metadata must contain a list of metadata "
"that describe the IR. For our purposes, we need to declare a metadata node "
"that assigns the \"kernel\" attribute to the LLVM IR function that should be "
"emitted as a PTX `kernel` function. These metadata nodes take the form:"
msgstr ""

#: ../../../NVPTXUsage.rst:605
msgid "For the previous example, we have:"
msgstr ""

#: ../../../NVPTXUsage.rst:614
msgid ""
"Here, we have a single metadata declaration in ``nvvm.annotations``. This "
"metadata annotates our ``@kernel`` function with the ``kernel`` attribute."
msgstr ""

#: ../../../NVPTXUsage.rst:619
msgid "Running the Kernel"
msgstr ""

#: ../../../NVPTXUsage.rst:621
msgid ""
"Generating PTX from LLVM IR is all well and good, but how do we execute it "
"on a real GPU device? The CUDA Driver API provides a convenient mechanism "
"for loading and JIT compiling PTX to a native GPU device, and launching a "
"kernel. The API is similar to OpenCL.  A simple example showing how to load "
"and execute our vector addition code is shown below. Note that for brevity "
"this code does not perform much error checking!"
msgstr ""

#: ../../../NVPTXUsage.rst:630
msgid ""
"You can also use the ``ptxas`` tool provided by the CUDA Toolkit to offline "
"compile PTX to machine code (SASS) for a specific GPU architecture. Such "
"binaries can be loaded by the CUDA Driver API in the same way as PTX. This "
"can be useful for reducing startup time by precompiling the PTX kernels."
msgstr ""

#: ../../../NVPTXUsage.rst:759
msgid ""
"You will need to link with the CUDA driver and specify the path to cuda.h."
msgstr ""

#: ../../../NVPTXUsage.rst:765
msgid ""
"We don't need to specify a path to ``libcuda.so`` since this is installed in "
"a system location by the driver, not the CUDA toolkit."
msgstr ""

#: ../../../NVPTXUsage.rst:768
msgid ""
"If everything goes as planned, you should see the following output when "
"running the compiled program:"
msgstr ""

#: ../../../NVPTXUsage.rst:796
msgid ""
"You will likely see a different device identifier based on your hardware"
msgstr ""

#: ../../../NVPTXUsage.rst:800
msgid "Tutorial: Linking with Libdevice"
msgstr ""

#: ../../../NVPTXUsage.rst:802
msgid ""
"In this tutorial, we show a simple example of linking LLVM IR with the "
"libdevice library. We will use the same kernel as the previous tutorial, "
"except that we will compute ``C = pow(A, B)`` instead of ``C = A + B``. "
"Libdevice provides an ``__nv_powf`` function that we will use."
msgstr ""

#: ../../../NVPTXUsage.rst:848
msgid "To compile this kernel, we perform the following steps:"
msgstr ""

#: ../../../NVPTXUsage.rst:850
msgid "Link with libdevice"
msgstr ""

#: ../../../NVPTXUsage.rst:851
msgid "Internalize all but the public kernel function"
msgstr ""

#: ../../../NVPTXUsage.rst:852
msgid "Run ``NVVMReflect`` and set ``__CUDA_FTZ`` to 0"
msgstr ""

#: ../../../NVPTXUsage.rst:853
msgid "Optimize the linked module"
msgstr ""

#: ../../../NVPTXUsage.rst:854
msgid "Codegen the module"
msgstr ""

#: ../../../NVPTXUsage.rst:857
msgid ""
"These steps can be performed by the LLVM ``llvm-link``, ``opt``, and ``llc`` "
"tools. In a complete compiler, these steps can also be performed entirely "
"programmatically by setting up an appropriate pass configuration (see :ref:"
"`libdevice`)."
msgstr ""

#: ../../../NVPTXUsage.rst:870
msgid ""
"The ``-nvvm-reflect-list=_CUDA_FTZ=0`` is not strictly required, as any "
"undefined variables will default to zero. It is shown here for evaluation "
"purposes."
msgstr ""

#: ../../../NVPTXUsage.rst:875
msgid "This gives us the following PTX (excerpt):"
msgstr ""
